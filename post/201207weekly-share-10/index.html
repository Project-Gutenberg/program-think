<!DOCTYPE html>
<html lang="zh-cn">

<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link rel="alternate" type="application/rss+xml" title="RSS" href="../../post/index.xml">
    
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:site" content="@SpeechFreedomCN">
    <meta name="twitter:creator" content="@SpeechFreedomCN">
    <meta name="og:title" content=" 每周转载&amp;#65306;关于人工智能对人类的影响&amp;#65288;网文3篇&amp;#65289; | 编程随想镜像站 " />
    <meta name="og:description" content="前几天是人工智能之父阿兰·图灵的100周年诞辰。考虑到纪念图灵的文章已经很多了，所以本周俺转载几篇人工智能相关的文章。
　这篇出自 IT 界预言帝凯文·凯利（Kevin Kelly）之手。他参与创办的《全球概览》杂志让乔布斯推崇备至（乔布斯的名言“Stay Hungry Stay Foolish”就是从该杂志看来的）；他创办的《连线》杂志在全球 IT 界举足轻重。 此文的原始标题是：《Will Spiritual Robots Replace Humanity by 2100?》
 　2000年4月，道格拉斯·霍夫斯塔特（Douglas Hofstadter）在斯坦福大学组织会议，讨论这个问题：“2100年智能机器人将取代人类吗？”与会者有比尔·乔伊（Bill Joy）、雷·库兹维尔（Ray Kurzweil）、汉斯·莫拉维克（Hans Moravec）、约翰·霍兰德（John Holland）和我。这是个严肃的问题。
我决定通过分析问题中的每个词来回答这个问题。
　2100
　我发现，尤其是在回顾有关科技的长期历史时，以人类的世代为标准大有好处。我粗略估算每25年为一代。文明开始于一万年前——最古老的城市耶利哥诞生于公元前8000年，它创造的文明如今在耶利哥和世界其它地区延续了约400代。那是400个由母亲到女儿的生育周期。文明人类的400代并不很长。如果没有别的事情可做，我们几乎可以背熟400个周期所有的名字。400代之后，我们已经成为不同于初期的人类。大约在8代之前，我们才有自动装置和机器人的概念，在两代之前才制造出第一部电子计算机。整个万维网的诞生还不到2000天！按同样的人类寿命计算，距离2100年只有四代。如果我们在2100年转变为机器人，那么文明的人类将仅延续400代。那将是生命历史上一个物种最短的寿命。
　人类
　在即将到来的世纪，核心问题（即主要问题）不是“人工智能是什么？”，而是“人类是什么？”人类有什么用？我预测，在即将到来的世纪，各种有关“人类是什么”的问题将成为《今日美国》之类报纸经常用到的标题。电影、小说、会议和网站都将设法解决这个核心问题，“我们是谁？人类是什么？”在长期繁荣的经济发展支持下，一切皆有可能，一切皆不确定，我们将遇到更多有关自己身份的问题，而不是这些问题的答案。我们是谁？男性或女性，父亲、美国人或人类是什么意思？下个世纪有可能被形容为大规模、全球范围的百年身份危机。到2100年，人们会为回溯到今天的我们人类感到惊奇，因为我们竟然知道人类是什么。
　取代
　取代在自然界很罕见。我们现在之所以拥有二百万个物种，正是因为大多数新物种并不会取代老物种，它们宁愿与现有的生物体交织起来，挤进小生境之间，以其它物种的成就为基础。创立一个新的小生境远比取代已被占居的小生境容易得多。大多数物种的灭绝不是因为有篡位者，而是因为其它因素，如气候变化、彗星或其自身造成的麻烦。取代或淘汰人类似乎不可能。假如我们不知道人类是什么，我们的角色就可能会改变，我们更有可能重新定义自己，而不是消失。
　机器人
　一般而言，我喜欢汉斯·莫拉维克（Hans Moravec）的确切阐述：这些机器人是我们的孩子。如何养育孩子？我们培养他们必然是为了放手。如果我们的孩子永远不离开我们的控制，我们不只会失望，而且会变得残忍。为了创新，为了富有想象力、创造力和自由，孩子需要脱离其制造者的控制。我们心目中的孩子——机器人也一样。一个家长，有一个得不到关心的孩子，他会一点都不担心吗？我们花了很长时间才认识到，科技的力量与其固有的失控及其固有的令人惊喜且具有生产力的能力成比例。事实上，除非我们不能再为科技操心，它的创新就没有尽头。强大的科技需要责任心。由于机器人具有繁殖能力，我们需要更强大的责任心。我们应该有目的地培养我们的机器人孩子成为好公民。也就是说，要逐渐为他们灌输价值观，以便在我们放开手时，他们能够作出负责任的决定。
　智能
　我们能够想象的最智慧的事情是什么？与一个外星人进行可验证的接触将动摇国教的基础。无论外星人给出的答案是什么，都将重新提出有关上帝的问题。我认为《接触》是唯一一部使神学者成为明星的影片。我们不必等待外星智能探索项目与外星人接触。我们将通过制造外星人，也就是说通过制造机器人来完成这个任务。这样一来，外星人就有了另一个名字：人工智能。担心人工智能成为人造人类的人大错而特错。人工智能将更接近于人工外星人。你的计算机在算法上已经比这个房间里任何人都更聪明了。为什么我们并没有因此而感到威胁？因为它是“另类”，是一种不同的智能，是比我们高级，而我们并不会特别妒忌的智能。我们创造的智能，包括最聪明的人工智能，大多数将成为“另类”。实际上，在各种有意识智能的可能空间，可能存在着两百万种其它智能物种，而不只是我们所知的一种（人类）——它们每一种都像计算机和海豚一样，是独特的、不同的。我们没有理由去克隆一个人类智能，因为制造传统版本的人类非常容易。在即将到来的世纪，我们要做的努力就是利用迄今为止所有的智能（人造的和自然的）创造所有可能的新智能。我认为迎接我想到的这些智能将是我们目前所能想象的最智慧的事情。
　会取代" />
    <meta name="og:image"
        content="https://opvlbqxurl.execute-api.ap-northeast-2.amazonaws.com/prod/random?keyword=programming&slug=每周转载&amp;#65306;关于人工智能对人类的影响&amp;#65288;网文3篇&amp;#65289;" />
    <title> 每周转载&amp;#65306;关于人工智能对人类的影响&amp;#65288;网文3篇&amp;#65289; | 编程随想镜像站</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-151212685-4', 'auto');
	
	ga('send', 'pageview');
}
</script>

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-151212685-4', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.7.1/css/bulma.min.css" />
    <link rel="stylesheet" href="https://project-gutenberg.github.io/program-think/css/blog.css" />
    
    <!-- plugins -->
    
    <link rel="stylesheet" href="https://project-gutenberg.github.io/program-think/plugins/bootstrap/bootstrap.min.css ">
    
    <link rel="stylesheet" href="https://project-gutenberg.github.io/program-think/plugins/themify-icons/themify-icons.css ">
    

</head>

<body>

    
    <nav class="navbar is-fixed-top" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
            <a class="navbar-item" href="https://project-gutenberg.github.io/program-think/">Home</a>
        </div>
        <div class="navbar-brand">
            <a class="navbar-item" href="https://project-gutenberg.github.io/program-think/post/index.xml">RSS</a>
        </div>
    </nav>
    

    
    <section class="hero is-info is-medium">
        <div class="hero-body" style="background-image: url(https://project-gutenberg.github.io/program-think/img/bg-blog.jpg);">
            <div class="container has-text-centered">
                <br>
                <h1 class="title is-size-1">
                    
                    每周转载&amp;#65306;关于人工智能对人类的影响&amp;#65288;网文3篇&amp;#65289;
                    
                </h1>
                
            </div>
        </div>
    </section>

<div class="container">
    <div class="section">
    

<div class="columns">
    <div class="column is-12">
        <div class="tile is-child box">
            

            <div class="content">
                <p>　　前几天是人工智能之父阿兰·图灵的100周年诞辰。考虑到纪念图灵的文章已经很多了，所以本周俺转载几篇人工智能相关的文章。</p>

<p>　　这篇出自 IT 界预言帝<a href="https://zh.wikipedia.org/wiki/%E5%87%AF%E6%96%87%C2%B7%E5%87%AF%E5%88%A9">凯文·凯利</a>（Kevin Kelly）之手。他参与创办的《全球概览》杂志让乔布斯推崇备至（乔布斯的名言“Stay Hungry Stay Foolish”就是从该杂志看来的）；他创办的《连线》杂志在全球 IT 界举足轻重。 　　此文的原始标题是：《Will Spiritual Robots Replace Humanity by 2100?》</p>

<blockquote>
<p>　　2000年4月，道格拉斯·霍夫斯塔特（Douglas Hofstadter）在斯坦福大学组织会议，讨论这个问题：“2100年智能机器人将取代人类吗？”与会者有比尔·乔伊（Bill Joy）、雷·库兹维尔（Ray Kurzweil）、汉斯·莫拉维克（Hans Moravec）、约翰·霍兰德（John Holland）和我。这是个严肃的问题。<br />
　　我决定通过分析问题中的<strong>每个词</strong>来回答这个问题。</p>

<p>　　<strong>2100</strong></p>

<p>　　我发现，尤其是在回顾有关科技的长期历史时，以人类的世代为标准大有好处。我粗略估算每25年为一代。文明开始于一万年前——最古老的城市耶利哥诞生于公元前8000年，它创造的文明如今在耶利哥和世界其它地区延续了约400代。那是400个由母亲到女儿的生育周期。文明人类的400代并不很长。如果没有别的事情可做，我们几乎可以背熟400个周期所有的名字。400代之后，我们已经成为不同于初期的人类。大约在8代之前，我们才有自动装置和机器人的概念，在两代之前才制造出第一部电子计算机。整个万维网的诞生还不到2000天！按同样的人类寿命计算，距离2100年只有四代。如果我们在2100年转变为机器人，那么文明的人类将仅延续400代。那将是生命历史上一个物种最短的寿命。</p>

<p>　　<strong>人类</strong></p>

<p>　　在即将到来的世纪，核心问题（即主要问题）不是“人工智能是什么？”，而是“人类是什么？”人类有什么用？我预测，在即将到来的世纪，各种有关“人类是什么”的问题将成为《今日美国》之类报纸经常用到的标题。电影、小说、会议和网站都将设法解决这个核心问题，“我们是谁？人类是什么？”在长期繁荣的经济发展支持下，一切皆有可能，一切皆不确定，我们将遇到更多有关自己身份的问题，而不是这些问题的答案。我们是谁？男性或女性，父亲、美国人或人类是什么意思？下个世纪有可能被形容为大规模、全球范围的百年身份危机。到2100年，人们会为回溯到今天的我们人类感到惊奇，因为我们竟然知道人类是什么。</p>

<p>　　<strong>取代</strong></p>

<p>　　取代在自然界很罕见。我们现在之所以拥有二百万个物种，正是因为大多数新物种并不会取代老物种，它们宁愿与现有的生物体交织起来，挤进小生境之间，以其它物种的成就为基础。创立一个新的小生境远比取代已被占居的小生境容易得多。大多数物种的灭绝不是因为有篡位者，而是因为其它因素，如气候变化、彗星或其自身造成的麻烦。取代或淘汰人类似乎不可能。假如我们不知道人类是什么，我们的角色就可能会改变，我们更有可能重新定义自己，而不是消失。</p>

<p>　　<strong>机器人</strong></p>

<p>　　一般而言，我喜欢汉斯·莫拉维克（Hans Moravec）的确切阐述：这些机器人是我们的孩子。如何养育孩子？我们培养他们必然是为了放手。如果我们的孩子永远不离开我们的控制，我们不只会失望，而且会变得残忍。为了创新，为了富有想象力、创造力和自由，孩子需要脱离其制造者的控制。我们心目中的孩子——机器人也一样。一个家长，有一个得不到关心的孩子，他会一点都不担心吗？我们花了很长时间才认识到，科技的力量与其固有的失控及其固有的令人惊喜且具有生产力的能力成比例。事实上，除非我们不能再为科技操心，它的创新就没有尽头。强大的科技需要责任心。由于机器人具有繁殖能力，我们需要更强大的责任心。我们应该有目的地培养我们的机器人孩子成为好公民。也就是说，要逐渐为他们灌输价值观，以便在我们放开手时，他们能够作出负责任的决定。</p>

<p>　　<strong>智能</strong></p>

<p>　　我们能够想象的最智慧的事情是什么？与一个外星人进行可验证的接触将动摇国教的基础。无论外星人给出的答案是什么，都将重新提出有关上帝的问题。我认为《接触》是唯一一部使神学者成为明星的影片。我们不必等待外星智能探索项目与外星人接触。我们将通过制造外星人，也就是说通过制造机器人来完成这个任务。这样一来，外星人就有了另一个名字：人工智能。担心人工智能成为人造人类的人大错而特错。人工智能将更接近于人工外星人。你的计算机在算法上已经比这个房间里任何人都更聪明了。为什么我们并没有因此而感到威胁？因为它是“另类”，是一种不同的智能，是比我们高级，而我们并不会特别妒忌的智能。我们创造的智能，包括最聪明的人工智能，大多数将成为“另类”。实际上，在各种有意识智能的可能空间，可能存在着两百万种其它智能物种，而不只是我们所知的一种（人类）——它们每一种都像计算机和海豚一样，是独特的、不同的。我们没有理由去克隆一个人类智能，因为制造传统版本的人类非常容易。在即将到来的世纪，我们要做的努力就是利用迄今为止所有的智能（人造的和自然的）创造所有可能的新智能。我认为迎接我想到的这些智能将是我们目前所能想象的最智慧的事情。</p>

<p>　　<strong>会取代</strong></p>

<p>　　我认为，科技有自己的日程表。我问自己的问题是，科技想要什么？概括地讲，如果说科技是个孩子，甚至是个青少年，能了解“青少年想要什么”确实是有益的。我们称为“科技”的这个系统，它的先天欲望、固有偏爱、内在驱动力是什么？一旦知道科技想要什么，我们就不必对所有这些需求让步，不必超过你所放任的青春期孩子的任何欲望。不过，你也不可能完全拒绝这些需求。科技“会”希望这些事情发生吗？我认为，它们希望其发生。我们所了解的科技是，它想更小（摩尔定律），它想更快（库茨维尔定理），我猜，科技想做人类所做的任何事情（凯利定律）。我们人类发现了其它生物的巨大价值，并逐渐发现其它智能的巨大价值。我认为，机器人没有理由发现不了人类也同样有价值。机器人能够，或者想要做一切人类所做的事吗？不，通常我们会让它们做我们不愿做的事。那么之后，我们人类做什么呢？机器人将第一次赋予我们力量说：我们想做的任何事。</p>
</blockquote>

<p>　　这篇的作者 <a href="https://en.wikipedia.org/wiki/Bill_Joy">Bill Joy</a>（<a href="https://zh.wikipedia.org/wiki/%E6%AF%94%E5%B0%94%C2%B7%E4%B9%94%E4%BC%8A">比尔·乔伊</a>）是技术大牛，他的头衔至少包括：SUN 联合创始人兼首席科学家，BSD 创始人，Sparc 芯片设计者，VI 之父（在俺<a href="https://program-think.blogspot.com/2013/01/weekly-share-37.html">谈“黑客”的另一篇博文</a>介绍过他）。 　　此文是他在2000年写的文章，谈及了：包括 AI 在内的高科技对人类未来的影响。内容很长，翻译得不太好 :( 另，文中的维基百科链接是俺标注滴。</p>

<blockquote>
<p>　　<strong>在21世纪，我们威力无比的三种科技：机器人、基因工程和纳米技术正在使人类成为濒危物种。</strong></p>

<p>　　自从我从事科技创造的那一刻起，我就关注其在伦理上的问题。但直到1998年秋天我才认识到我们在21世纪面临着多大的危险。这一不安始于我遇到雷·库兹维尔（<a href="https://en.wikipedia.org/wiki/Ray_Kurzweil">Ray Kurzweil</a>），一位伟大的发明家，发明了为盲人服务的阅读机，还有许多不可思议的机器。</p>

<p>　　我和雷（Ray Kurzweil）都是在佐治亚州Gilder市召开的远程通讯大会的发言者。会议结束后，我在旅店酒吧与他偶遇。当时我正在与约翰（John Searle），一位在加州大学佰克利分校研究意识问题的哲学家，坐在一起聊天。雷（Ray Kurzweil）走过来与我们攀谈起来。直至今日，我们谈论的内容依然困扰着我。 　　我没有听到雷（Ray Kurzweil）的演讲及其后来的座谈，而约翰（John Searle）有，他们现在重拾未完的话题。雷（Ray Kurzweil）认为技术进步的速度将会越来越快，我们将会成为机器人或者与机器人结合的合成人，或者与之类似的东西。但约翰不以为然，他认为这不可能发生，因为机器人不会有意识。 　　在听到这样的谈话之前，我一直认为有感觉的机器人只存在于科幻小说中。但现在，从一些值得尊重的人那里，我知道了那些机器人已经离我们不远了。我大吃一惊，特别是我知道雷（Ray Kurzweil）已经证明自己有资格有能力描绘并创造出这一未来。我现在已经知道新科技，比如基因工程、纳米技术，能帮助我们重新改造这个世界，但智能机器人的现状与未来使我感到惊奇。 　　诸如此类的技术突破会使人厌倦。我们几乎每天都能听到关于科技进步的新闻。但这次可不是一般的预言。在旅店的酒吧里，雷（Ray Kurzweil）给了我一本他即将出版的新书《智能机器的时代》的预印本。他在这本书中勾勒出了他心目中的乌托邦：通过机器人技术，人类将会得到几乎永生不灭的生命。在阅读这本书时，我心中的不安越来越强烈。我敢肯定，雷（Ray Kurzweil）低估了机器人技术的危险性，低估了这一技术造成严重后果的可能性。 　　我发现以下反乌托邦情景让自己寝食难安： 　　新卢德主义的挑战 　　首先让我们假定计算机科学家开发出了比人类更能干的智能机器。在这种情况下，所有的工作将由大量组织良好的机器系统完成，而人类不再需要进行劳动。我们可能会充许机器自主地作出决定，或者人们依然保留对机器的控制。这两种情况都有可能发生。 　　如果允许机器自主运行，由于我们不可能猜测出机器是如何得出结论的，所以也就无法推测这一结果。我们将会发现人类的命运将掌握在机器手中。也许有人会争论说人类不会愚蠢到把所有的权力移交给机器，但我们正在谈论的既不是人类把权力让度给机器，也不是机器有意攫取权力。我们谈论的是人类很容易陷入不得不接受机器的自主决定，从而依赖机器生存的境地。随着社会及其面对的问题越来越复杂，并且机器的智能越来越高，人类将让机器作出越来越重要的决定，不为其他，只是机器作出的决定要比人类明智得多。最终，由于保持系统正常运行的决策是如此复杂，人类的智能再也无法承担，而机器却能胜任愉快。人们再也无法简单地拨掉机器的电源，因为我们是如此依赖机器，关机无异于自杀！ 　　另一方面，人类保持对机器的控制是有可能的。比如，在上面所说的情况下，相当部分的人仍然控制私人拥有的机器，象汽车、个人电脑之类。但控制大型机器系统的是极少数精英阶层，就象当今社会一样。但与现在相比有两点不同：由于科技进步，精英阶层对广大群众有了更大的控制权，并且由于人类劳动不再是必需的，广大群众也变成了整个系统无用而多余的负担。如果精英阶层是冷酷无情的，他们可能会简单地把这些人消灭殆尽。如果他们是仁慈的，可能会用宣传或其他精神上、生物上的技术来降低人口出生率，直至这些人灭绝，从而完全拥有这个世界。还有另外一种可能性，如果精英阶层是软心肠的自由主义者，他们可能会扮演牧羊人的角色来照顾其余的人类。他们将会满足每个人肉体上的需要，让孩子们健康地成长，每个人都会忙于有益身心健康的爱好，任何对此不满意的人都会受到“特殊照顾”以纠正他们的“问题”。当然，生命是如此没有意义，以至人们不得不接受生物或精神上的改造以去除他们对权力的欲望，或者使之“升华”成无害的嗜好。这些经过改造的人类在这样的社会中也许会感到快乐，但他们肯定是不自由的，他们就像动物园中被饲养的动物。</p>

<p>　　直到你读到这一页，你才发现以上内容的作者是<a href="https://zh.wikipedia.org/wiki/%E6%B3%B0%E5%BE%B7%C2%B7%E5%8D%A1%E8%BE%9B%E6%96%AF%E5%9F%BA">泰德·卡辛斯基</a>，著名的“大学炸弹客”。我并不是卡辛斯基的辩护者。在他17年的恐怖活动中，用炸弹夺走了3个人的生命，还炸伤了很多人。其中一枚炸弹使我的朋友 David Gelernter 严重受伤，戴维是我们这个时代最具天才与想象力的计算机科学家。就象我的很多同事一样，我感到我很有可能就是“大学炸弹客”的下一个袭击目标。</p>

<p>　　卡辛斯基的行为是谋杀和愚蠢的罪行。毫无疑问，在我眼中他是个<a href="https://zh.wikipedia.org/wiki/%E7%9B%A7%E5%BE%B7%E5%88%86%E5%AD%90">卢德主义者</a>，但简单地下此结论难以驳倒他的观点。虽然很难，但在上面一段论述中，我还是察觉到了一些真相，我感到我有责任来面对它。</p>

<p>　　我们不希望卡辛斯基想象的反乌托邦成为现实，但一个众所周知的关于设计与技术应用的问题可以用“墨菲定律”来描述：“会出错的，终将会出错”（事实上，应当称之为菲纳络定律，这一错误本身就证明了菲格纳真是英明无比！）抗生素的过度使用已经造成最严重的问题：抗生素耐药性危机和越来越多的危险细菌。与之类似的事情曾经发生过：想用DDT杀死传播虐疾的蚊子，却使之产生DDT耐药性，其幼虫也获得了对多种药物的耐药性基因。 　　诸如此类令人惊奇的事故清楚地表明：系统各部分相互之间的作用与反馈太过复杂，对系统的改变会引起连锁反应，难以预料最终结果。特别是把人类的活动也考虑进来后，情况就越发复杂了。 　　我开始向朋友们介绍《智能机器的时代》一书对对卡辛斯基言论的引用；我递给他们卡辛斯基的书，让他们阅读这些引文，然后观察当他们发现是谁写下这些文字时的反应。大约在这一段时间，我发现了汉斯·莫拉维克（Hans Moravec）的《机器人——通往非凡思维的纯粹机器》。莫拉维克是机器人研究领域的领军人物，他在卡耐基·梅隆大学创立并领导着世界上最大的机器人研究计划。这本书给了我更多的材料来考验我的朋友们。令人惊奇的是，那些材料大多支持卡辛斯基的论调。例如：“近期（2000年早期）”一章：</p>

<p>　　<em>生物物种在遭遇到占优势的竞争者时几乎毫无生存的机会。一千万年以前，南北美洲被巴拿马地峡分开。南美洲就象今天的澳大利亚，到处繁衍着有袋类哺乳动物，有袋鼠、袋鹿和袋虎等等。当连接南北美洲的地峡升起后，北方在新陈代谢与神经系统上只占很少优势的胎生物种只用了几千年的时间就替换并灭绝了几乎所有的南方有袋类物种。</em></p>

<p>　　在完全自由竞争的市场上，占优势的机器人就会象北美胎生物种影响有南美有袋类物种一样影响人类的生存（也好象人类曾经影响无数其他物种一样）。机器人工业将会为了原材料、能源和空间展开激烈的竞争，其结果就是机器人的经济性超过人类。由于无法负担生活所需，人类将会被排挤出生存空间。 　　可能还有可能给人类留下喘息的空间，因为我们并不是生活在一个完全自由竞争的市场中。政府会强制执行一些非市场化政策，特别是税收。通过这一明智之举，政府的强制措施能支持人类在机器人劳动成果的基础以一种较高的生存状态繁衍生息。这一情况可能会持续很长时间。 　　这真是一本反乌托邦的生动教材，并且会让莫拉维克感到很不舒服。他继续讨论我们在21世纪的主要是：“制定法律来规范机器人工业的行为，确保与其持续的合作”。并描述了“一旦人类转变为毫无约束的超级智能机器人”会产生多么严重危险。在莫洛维克的观点里，机器人最终会战胜我们，人类毫无疑问将面结灭绝的命运。 　　我决定在此时此刻与我的朋友丹尼·希里斯（Dany Hillis）好好谈一谈。丹尼是生产并行超级计算机的Thinking Machines公司的创始人之一。我不光是太阳微系统公司的首席科学家，同时也是一个计算机设计者。丹尼在信息和物理科学方面的知识超过我认识的每一个人。丹尼还是一位值得关注的未来学家，他对未来进行了很长时间的思考，并在四年前创立了Long Now Foundation，他还为过去10000年制造了一台时钟，尝试刻画出人类历史上值得纪念的时间段（见“Test of Time”《时间测试》，《连线》2003年8月78页）。 　　因此我飞到洛杉矶与丹尼夫妇共进午餐。我倾其所有，向丹尼提出了一些困扰我的想法我思路供其考虑。丹尼的回答直指库兹维尔（Ray Kurzweil）设想的未来情景：人类与机器人合二为一的时代很快就会到来。这一回答令我大吃一惊。总而言之，他认为这一变化会逐渐成为现实，人们迟早对此会习以为常。 　　但我认为我没有完全地感到惊奇。我从丹尼那听到了对库兹维尔（Ray Kurzweil）书中内容的引用。他说：“虽然我象别人一样喜爱自己身体，但是如果我能依靠硅基肉体活上200岁，我会毫不犹豫地放弃它。”看上去丹尼已经对一变化过程及随之而来的危险听天由命了，而我却不能。 　　当谈论与思考关于库兹维尔（Ray Kurzweil）、卡辛斯基及莫拉维克（Hans Moravec）的事情时，我突然想到了20多年前读过的一本弗兰克·赫伯特（Frank Herbert）的科幻小说《白色瘟役》（The White Plague）。在小说中，一位分子生物学家因其父母妻儿被无原无故地谋杀而陷入疯狂。为了报复，他制造并散布了一种新研制的高度传染性的瘟役，用它来杀死很多经过选择的人（我们应当庆辛卡辛斯基只是个数学家，而不是分子生物学家）。我还记得《星际迷航》（Star Trek）中的博格人（Berg），一种具有毁灭倾向的半人半机械生物。类似博格人的灾难是科幻小说中经常出现的情节。这就是我为什么更早更关注这样的机器人反乌托邦的原因。为什么其他人不为这梦魇般的未来世界操一点心呢？ 　　这一问题的部分答案在于我们偏狭的劣根性：喜欢新奇的东西、马上就能上手的东西、毫无诫心地接受它们。习惯于每天听到的科技新发现。我们已经处于这样一个阶段：21世纪最引人注目的科技：机器人、基因工程和纳米技术，在其到来之前就已经表面出了与众不同的巨大威力，特别是机器人、经过基因工程改造过的有机体、纳米技术具有相同的使危险扩大的因素：它们能自我复制。一枚炸弹只能响一声，但一个机器人能就自我复制成很多个，很快就会失去控制。 　　在过去25年中，我的大部分工作是计算机网络研究。在网络上发送与接收信息会造成失控复制。虽然计算机或计算机网络上的失控复制很讨厌，但是在最坏情况下也不过是使单台计算机无法正常工作或阻塞网络通讯、网络服务。而那些更新科技产品的失控自我复制会造成更大危险：它们会损害到物理世界。 　　这些科技都提出了数不清的美好承诺：库茨维尔在其机器人梦想中看到的近乎长生不老的前景激励我们不断前进，基因工程很快就能为大多数不能很快痊愈的疾病提供了治疗方法；纳米技术和纳米医疗能治愈更多疾病。所有这一切将会极大提高我们的平均寿命及生活质量。然而，对于其中任何一项技术，持续不断地微小、个别的进行会积累成威力巨大的力量及其伴随而来的巨大的危险。 　　20世纪有何与众不同？当然，产生大规模杀伤性武器（WMD）核武器、生物武器、化学武器的科技极具威力，并且这些武器具有巨大的威胁性。但建造核武器至少需要时间、稀少、事实上不可能得到的原材料以及高度保密的资料；生物武器和化学武器的研制也需要开展大规模的活动。 　　而21世纪的技术——基因工程、纳米技术和机器人（GNR）的威力是如此巨大，它们会孕育出新的事故及滥用方式。最危险的是，这些事故与滥用首先会在个人或小型组织就能企及的能力范围内。它们不需要巨大的开发能力或稀少的原材料，只要有相关技术知识就能利用它们。 　　因此，我们不光受到大规模杀伤性武器的威胁，还有技术知识产生的大规模杀伤力，它们的自我复制能力极大地扩展了其杀伤力。 　　我想以下所说绝对不是危言耸听：我们人类面临产生极端邪恶的最高可能性，这一邪恶的产生正由国家力量支持的大规模杀伤性武器转而到恐怖的极端个人。</p>

<p>　　<strong>没有什么指出我们将面对这样的问题。</strong></p>

<p>　　我的生命被内心深处的热情驱使着，提出问题、找寻答案。当我3岁时，我已经开始阅读。所以我的父亲把我送进了小学，我那时只能坐在校长的腿上听他讲故事。我很早就开始上学，然后跳级。我凭着难于置信的热情投入到书本之中进行学习，我提出了很多让大人们都很难解决的问题。 　　作为一个十多岁的少年，我对科技技术非常着迷。我希望成为一名“火腿”（业余无线电爱好者），但我没有钱买设备。“火腿”是那个时代的因特网，非常容易上瘾，也使人离群索居。暂且不论有没有钱，我母亲马上表示坚决反对，我不能成为一名“火腿”，因为我已经够孤僻的啦！ 　　那时我没有什么亲密的朋友，但我沉醉在我丰富的想像之中。我中学时代，我发现了许多伟大的科幻小说家。特别是我仍然记得Heinleain的《穿着太空服去旅行》（Have Spacesuit with Travel）和阿西莫夫的《我，机器人》及其机器人三原则。我被关于太空旅行的描写深深迷住了，就想拥有一架望远镜来看一看天上的星星；由于我没有钱买或制作一架，我就从图书馆借来关于如何制造望远镜的书，通过阅读来安慰自己。我在想像的空间中自由翱翔。 　　星期四晚上我的父母会出去打保龄球。而我们这些小孩独自待在家中。星期四晚上是吉恩·罗顿巴里（Gene Roddenberry）最初的《星际迷航》（Star Trek）播出的时间，这个节目给我留下了深刻的映象。我开始接受这样一种理念：人类未来将在太空进行西部英雄式的冒险。罗顿巴里描绘的几个世纪后的情景有着重要的道德价值：遵守“第一守则”，不要干预任何技术水平较低的文明的发展。这些对我有着不可否认的吸引力；是精英人类，而不是机器人会支配我们的未来。罗顿巴里梦想成为我生命中不可或缺的一部分。 　　最脍炙人口的电视科幻片集《星空奇遇》，其中述及太空合众国的所有探险队都要遵守一条「第一守则」（prime directive），那就是。在未调查清楚及未得太空合众国批准前，不得干预任何文化水平较低的族类的自然发展。 　　高中时我的数学相当不错，并且在密歇根大学工程专业读书时，我已经学习了研究生的高等数学课程。解决数学问题是一种令人兴奋的挑战，但当我发现了计算机以后，我觉得它更加吸引我：你能把用以解决某个问题的程序放入到一台机器里，然后这台机器很快就能判断出你的解决方案是否正确。计算机的答案非常清楚：正确或错误、真或假。我的想法正确吗？机器会告诉你一切。这真是太吸引人了！ 　　我非常幸运地得到了一个在早期超级计算机上编程的工作。我发现大型计算机在对复杂设计方案进行数字化模拟方面有着不可思议的威力。当我在70年代中期到加州大学伯克利分校上研究生时，我开始在机房里待很长时间，常常是通宵达旦。我在计算机中发现了一个新世界，我在里面解决各种问题，编写被认为是很难的写出的代码。 　　在欧文·斯通（Irving Stone）为米开朗基罗写的传记小说《痛苦与狂喜》中，斯通生动地描写了米开朗基罗是如何从石头中解放出了雕像，“破除石化咒语”,依照心灵的指引切开巨石。在我大多数狂喜的瞬间，计算机中的软件也是如此完成。我曾经在我的心中这样描述：我感到那些软件已经“封印”在机器中，等待着我为它们破除咒语。而夙兴夜寐的辛劳与此相比不值一提。 　　在伯克利待了几年后，我开始向另外一些使用类似小型 PDP-11 和 VAX 微型计算机的同仁提供自己写的一些软件：一个教育用 Pascal 编译器、一些 UNIX 程序和名为 VI 的文本编辑器（令人吃惊的是，到现在已经20多年了，它仍然被广泛地使用）。在这些软件上的探索最终形成了伯克利版本的UNIX，由此产生了我个人的“成功之灾”：太多的人想要得到它，以至于我没能完成我的博士学位。幸好，我得到了一份为 DARPA（美国国防部先进计划研究局）把 UNIX 系统应用到因特网上的工作，我的任务是使 UNIX 系统更加可靠，并能运行很多大型应用软件。这一工作非常有意思并有很高的报酬。并且，坦白地说，我没有在这个项目中或别的什么地方看到什么机器人。 　　随后，直到1980年早期，我一直潜心学习。UNIX系统的发布版非常成功，我的小项目很快有了钱和一些工作人员，但在伯克利，办公室总是比金钱要少得多；那儿不能为我的计划提供所需的房间，所以，当 SUN 微系统公司的其他创始人出面邀请我时，我就加入了他们。在 SUN 公司，我们为早期的工作站与个人计算机投入了大量时间，我则醉心参与先进微处理器技术与 Java、Jini 之类因特网技术的开发。 　　从所有这些事情中，我相信我决不会是个卢德主义者。我一直坚信为寻找真理而进行科学研究的价值和为改进物质条件而进行大规模工作实践的可能性。在过去几个世纪，工业革命曾经不可限量地改善了每个人的生活质量。我一直希望我的事业能够为解决有关国计民生的问题作出一份贡献。 　　我从来没有感到悲观失望。我的工作比我希望的更有影响，比我想到的应用更广泛。我用去20多年的时间使计算机能象我希望的那样可靠（目前它们几乎还不能达到这一目标），并且更加简便易用（这一目标取得了相对成功）。除去一些有限的技术进步，这些问题依然在那里，甚至看上去更加难以解决。 　　当我关注用于武器研究的技术成就的道德困境时，我不希望我自己的研究领域也会面对这样的问题，至少不是马上。 　　当一个处于风暴中心时，他很难对形势作出正确的判断。作为科学家和技术人员，当我们处于发现的狂喜之中时，我们看不到我们的发明所造成的后果。我们长久以来被求知的欲望驱驶，我们停不下脚步，这是科学家的天性，如果仅此而已，那我们就是不称职的科学家。现在我们要告诉大家：更新更具威力的科技进步最终会压跨生命本身！ 　　长久以来，我认识到在信息技术领域的进步不是来自于计算机科学家、计算机设计师或电子工程师，而是来自于物理学家。在1970年早期，物理学家斯 Stephen Wolfman 和 Brosl Hasslacher 向我介绍了浑混理论和非线性系统。1990年我在与 Danny Hillis、生物学家 Stuart Kauffman、诺贝尔物理学奖获得者 Marray Gellmane 及其他人的交谈中了解到了复杂系统的有关知识。Hass Lacher 和电子工程师、实验物理学家 Mark Reed 让我领略到了分子电子学不可思议的应用前景。 　　在我自己的工作中，作为三种微处理器架构：SPARC、picoJava、MAJC 的设计者之一，并且作为以上架构的若干种实现的设计者之一，我亲自感受至了摩尔定律。在过去数十年间，摩尔定律精确地预测了半导体技术的指数级增长。直到去年，我仍然想信在一些物理极限达到之前，摩尔定律到2010年前仍能精确地预测半导体技术的增长率。我并不认为到时会有新技术来保持半导体技术平稳地前进。但最近分子电子学以及相关纳米技术方面的快速而根本的进展，使得我们能用单个原子和分子取化平面蚀刻二极管，这样我们就能在另外一个30年内保持甚至超越摩尔定律。我们就有希望建造比现在个人电脑强大百万倍的机器，足以实现库茨库尔和摩洛维克的梦想。 　　当强大的计算能力与物理科学的进步、对基因深入了解及其巨大进化能力结合到一起时，无论是好是坏，是福是祸，我们已经完全有能力改变这个世界：被束缚在自然界中的复制与进化机制现在已经可以由人类操控了。 　　我在设计软件与硬件时，从来没有感觉到我是在设计智能机器。软件与硬件是如此脆弱，机器“思考”的能力是如此差劲，就算考虑进它们可能达到的水平，也离上述的未来太遥远。 　　但现在，随着人类水平的计算能力在过去30年中的飞速发展，在我的脑海中一种新的想法浮现出来：可能我们努力开发出来的工具将帮助那些能够取代人类自身的技术成果孕育成熟。我对此有何感受？我非常不安。我奉献出我的一生建造可靠的软件系统，对我而言，某些人描绘未来世界最好不要出现。我的个人经验告诉我，我们总是对自己设计的设计能力评价过高，而设计中微小的失误就会造成不可挽回的损失。 　　我们给了这些技术不可思议的强大威力，那我们该如何与它们和平共处呢？我们自己的技术发展也许会，甚至极有可能导致自身的来绝，难道我们还不应当小心翼翼地前进吗？ 　　起初，机器人之梦就是智能机器能为我们干所有人类能干的工作，使我们能悠闲生活，重返伊甸园。而 George Dyson，机器人世界中的达尔文，在研究这一梦想的过程中发出警告：“在生命及其进化的游戏中有三个玩家——人类、自然，还有机器。我坚定地站在自然一边；但自然，我怀疑它是站在机器一边的。”正如我们在上面看到的，莫拉维奇就相信我们可能不会在遭遇到占优势的机器人种族时幸存下来。 　　还有多长时间会出现智能机器人？在即将到来的计算机能力将使之在2030年成为现实，并且，一旦一台智能机器人出现，这对机器人种族来说只是很小一步，但这台机器人自身来说，它能马上产生无数自身经过进化的复本。 　　关于机器人的第二个梦想是我们将逐步用机器人技术取代自己的身体，通过下载我们的意识而达到永生不死。这就是丹尼尔—Hillis所描绘的我会正在慢慢适应的世界前景；雷·库兹维尔（Ray Kurzweil）在《智能机器的时代》一书中的描述的细节。（我们已在《连线》杂志8.02的封面上描绘的计算机设备到人类身体的移植上初见端倪） 　　但是，如果我们被下载到我们的科技设备之中，我们还有机会成为我们自己，甚至人类吗？我认为以机器人形式存在的绝不会是我们理解的人类个体，机器人绝对不会成为我们的孩子。 　　基因工程承诺在减少杀虫剂使用量的同时通过提高农作物产量来使我们的农业发生天翻地覆式的革命；创造成千上万种新型细菌、植物、病毒和动物；通过克隆技术替代自然生殖或增强自然生殖能力；治愈疾病，增加我们的寿命与生活质量；还有很多很多。我们现在确切地知道这些生物技术中的深刻变革即将到来，并将挑战生命是什么的传统观念！</p>

<p>　　象人体克隆之类的技术已经使我们分外关注即将面对的伦理与道德问题。打个比方，如果我们使用基因工程技术改造我们的自己身体，或者改造不同的人群、种族，那我们就会摧毁我们民主政治的基石——<strong>平等</strong>。</p>

<p>　　毫无疑问，基因工程巨大的威力会在其使用过程中带来严重的安全问题。我们的朋友 Amory Lovins 最近与 Hunter Lovins 合作写了一篇社论，他们从生态学的观念考察了这类危险。在他们所关心的问题中：“新植物学”（见《两个植物学家的故事》247页）。 Amory 在其漫长的职业生涯中一直关注从人造系统的整体观点研究能量及资源效率；这样的整体系统观念常常发现以别的方式看上去非常困难的问题有着简单而高明的解决方法。这种方式也能在此得到很好的应用。 　　读完 Lovins 的社论后，我看了 Gregg Eusterbrook 在《纽约时报》（1999年11月9日）发表的关于基因改良稻的非定官方评论。在大标题下写着：</p>

<p>“_未来的食物：除非卢德主义者胜利了，否则总有一天稻米将含有丰富的维生素。_”</p>

<p>　　Amory 和 Lovins 是卢德主义者吗？当然不是，我相信我们都同意：只要我们适当地关注在物种之间转移基因所带来的危险，“金稻”及其内含的维生素A对我们是有利的。 　　我们正在逐渐提高对基因工程与生俱来的危险性的关注程度，就象 Lovins 的社论所带来的反应。一般公众现在正很难得地在关注着基因改良食物，而且看上去他们不同意对这类食物不作特别标识的作法。 　　但基因工程技术已经走得太远了。在 Lovins 的备忘录中，USAP（美国农业部）已经批准了大约50种改良作物可以不受限制地扩散，世界上有超过一半的大豆和三分之一的玉米现在已经含有来自其他生物的基因。 　　在这里，非常非常重要的是，我所关注的基因工程领域，还有更重要的是，无论是军事上的，还是事故，还是蓄意的恐怖袭击，基因工程都给了他们制造白色瘟疫的强大能力。 　　纳粹技术的许多奇迹第一次被描述是在1959由诺贝尔物理学获奖者理查德·费曼（Richard Feynman）的一次演讲上，随后，以《底下还大有可为》出版了这篇演讲稿。在80年代中期，给我留下深刻映像的是 Eric Drexler 的《创造引擎》，在这本书中，他生动了描绘了原子级的物质生产，创造出了多么美好的乌托邦。在那里能非常方便地生产每一样东西。使用纳米技术我人工智能，几乎任何一种你能想像得到的疾病或身体上的缺陷都会得到完美的解决。 　　接下来的一本书，《解放未来——纳米技术革命》，由 Diexler 参与写作，描绘了一个拥有分子级别“装配工”的世界中所发生的变革。“装配工”能生产成本低到不可思议的太阳能、通过增强人体免疫系统来治疗癌症和感冒，完全彻底地清洁环境，生产价格低到难于置信的、小到可发装到口袋中的超级计算机。事实上，任何由“装配工”生产的产品都不会比用木头生产的成本更高，太空飞行将比现在的越洋飞行更加方便，并且还能复活已经灭绝的物种。 　　我记得我读完了《创造引擎》后，感觉还不错。作为技术人员，这本书让我感觉平静，也就是说，这本书向我展示的不可思议的纳米技术是可能的，确实也是不可避免的。如果纳米技术是我们的未来，我就不会对眼前这些问题有紧迫感。我就会到时顺理成章地进入 Drexler 的乌托邦，我就会在此时此刻尽情享受生活。我现在没日没夜地辛苦工作在他的未来中根本就毫无意义。 　　Drexler 的想像也带来了很多乐趣。我有时也向没有听说过纳米技术的人描绘一下纳米技术的奇迹。在用 Drexler 描述的东西调侃一下他们后，我还给他们一个我个人的课后作业：</p>

<p>“_用纳米技术建造一个帝国；但是你要想得到学分的话，就要再建造一个能摧毁它的力量。_”</p>

<p>　　我十分关心这些与奇迹伴随而来的明显的危险。正如我在1989年纳米技术大会上所说的：“我们不能单单只顾埋头研究科学而不关心与之相关的道德问题。”但在下一个物理学家参加的会议上，他们使我相信纳米技术甚至不能正常运作，或者，至少不能在任何时间都能正常运作。 　　随后，我移居到科罗拉多州，进行一项我领导的 skunk 工作。我的工作重点转向了因特网软件，重点是最后形成 Java 和 Jini 的一些想法。 　　在我任期将满的那个夏天，Brosl Hasslacher 告诉我纳米分子电子学已经实用化了。这的确是个新闻，至少对我来说是如此。我想对许多人来说也是这样。这一消息彻底改变了我对纳米技术的看法，让我不由自主回想起了《创造引擎》。在10年之后重读 Drexler 的著作，我沮丧地发现我记得其中冗长的一章《危险与希望》的很少很少一部分。在这一章，作者指出纳米技术可能会成为“毁灭的引擎”。在今天重读这段警世名言时，我对 Drexler 提出的如此天真的防卫方案感到惊奇！并且我认识到的危险性要比他当时所认为的大得多！（由于预言并描绘了纳米技术带来的众多技术和政治问题，Drexler 在80年代末创立了 Foresigh 研究所，用以帮助社会大众迎接即将到来的先进科技—其中最主要的是纳米技术。） 　　使“装配工”成为可能的技术突破很有可能在下一个20年内实现。在未来10年内，分子电子学，能把单个分子排列成为电路器件的纳米技术，很快就会成熟并成为非常有利可图的技术成果，并招致对纳米技术各个领域投资的大幅增长。 　　但不幸的是，就象核技术一样，用纳米技术来进行破坏活动要比进行建设活动容易得多，纳米技术在军事或恐怖袭击活动中有着十分明确的用途，并且恐怖分子不需要用自杀性攻击方式来释放大规模杀伤性纳米技术装置，他们能建造具有选择性破坏能力的纳米装置，例如仅仅对特定地区或者具有显著基因、生物特征的人群。 　　为了得到纳米技术巨大威力而进行的浮士德式的交易的直接后果就是我们正在玩火——我们可能会毁掉包容万物的生物圈。 　　而 Drexler 却如是说： 不比现在的太阳能电池板效率更高，“有叶树木”会排挤掉正常的树木，即那些到处都是而又不能食用的树木。粗野而又无所不能的“细菌”会排挤掉真正的细茵，它们象风中的花粉一样传播、快速地繁衍，并且把生物圈中生命降解成象灰尘一样的东西。如果我们没有做好准备，危险的复制者可能会太粗野、太小、太快地传播而失去控制。对我们来说，即使是控制病毒和花粉就已经让我们伤尽脑筋了。 　　在熟知纳米技术的人中，这种“灰胶”的威胁，以“灰胶问题”而广为人知。尽管大量失去控制的“复制者”既不是“灰”色，也不呈“胶”状。但“灰胶”这个名词是指“复制者”能涂去可能比杂草 crabgrass 更少生气的生命。它们可能在生物进化是优胜者，但这并不会使它们高人一等。使这一事实更加明白无误：我们负担不起此类“复制装配工”引起的事故。 　　比起天降火球或冰雪覆盖，“灰胶”极有可能是我们人类在地球上冒险生涯的悲惨结局。而这一切可能仅仅由于一次简单的实验室事故。 　　在基因工程、纳米技术和机器人（GNR）中的毁灭性的自我复制威力极有可能使我们人类发展嘎然而止。自我复制是基因工程的一种主要研究方法，它利用细菌的自我复制机制，而主要的危险来自于纳米技术的“灰胶”。横行霸道的机器人的故事，比如《星际迷航》中的博格人，通过复制或变种来脱离其制造者施加的道德约束，这一情景在我们的科幻小说与科幻电影中表现得淋漓尽致。自我复制的本能可能比我们想象得更加贴近物质本性，因此也就更加难以控制，如果我们还有机会来控制话。Sturoot Kauffman 最近在《自然》杂志上发表了一篇名为《自我复制：缩氨酸也能行》的文章，他在文章中指出 32-amino-acid 缩氨酸能“自我催化自身组织”。我们不知道这一能力在自然界有多广泛，但 Kauffman 认为这一现象提示我们“自我生产分子系统方式比沃森·克里克”的双螺旋 base-pairing 要基本得多。 　　事实上，我们多年以来已经得到了明确无误的警告：广泛传播的GNR知识带有与生俱来的危险性。仅仅只需要知识就能造成大规模的破坏。但这些警告还没有广为人知；很明显，公众对此没有足够的关注，而传播有关这一危险的信息对许多人来说却又无利可图。 用于制造二十世纪大规模杀伤性武器的核技术、生化技术（NBC）在过去与现在都是由政府机构开发的军事技术。与之完全相反的是，21世纪的GNR技术具有很明确的商业用途，毫无例外都是商业公司企业在进行研发。在这个商业主义大行其道的时代，只要能得到最大的收益，以科学作为自己奴仆的技术进步就能释放出魔幻般的发明创造。在现在全球化主义及其多样化的金融动力及竞争压力下，我们不加思索地就做出决定来开发这些新技术。 　　这是在我们星球的历史上第一次出现某种生物出于自愿而使其他许多物种陷入绝境。 　　这可能是很常见的过程，在许多世界中流传，一个才形成的星球，平静地在星河中忽隐忽现，生命慢慢形成；接下来是万花筒般的生物进化世纪；智能逐渐浮现；终有一天，生物靠此度过险境；然后技术发明出来；自然法则逐渐被了解；这些法则来自于实践，有关这些法则的知识以空前的速度被保存、被传播；它们认识世界、获取无边的动力；就象电光一闪，它们已经创造出能改变世界的发明；一些行星上的文明之路漫长而曲折，前途时而是一失足成千古恨的独木桥，里面是任意驰骋的阳关道；它们中有一些安全地度过艰难岁月，而有些却不是如此幸运或谨慎而遭到灭顶之灾。 　　这是事实，Sagan 在1994年出版的《暗淡的蓝点》一书中所说的，这本书描绘了人类在宇宙中的未来命运。我到现在才认识到，他的眼光是如此深邃，我已经，还有将来会错过他的教诲。对于所有这些至理名言，Sagan 的贡献并不仅仅是简单的常识，许多21世纪技术的领先者看上去缺少这种谦逊品质。 　　从小我就记得我的祖母强烈反对滥用抗生素。她从一次大战前就开始从事护士工作。作为一名护士，除非绝对必须，使用抗生素是对人有害的。 　　这并不是说她是进步的敌人。她在70年的护士生涯中看到了许多技术进步。我的祖父是一个糖尿病人，在其有生之年，人从已经证实确实有效的治疗方法中获益不浅。但我的祖母，就象其他头脑清醒的人一样，也许会认为在我们很明显无力应付相对较简单的工作，并为管理或者理解我们自身伤尽脑筋时，却想着要发明一种机器人“替代物种”，这是不是太狂妄自大了？ 　　我现在认识到她已经了解了这个众生各安天命的自然界，万物依天命而生，并对自然充满敬畏。伴随着由敬畏而来的谦逊，伴随着21世纪早期的chatipah，我们才不会过于胆大妄为。 　　扎根于这一敬畏的常识、观点一般是正确的，胜过科学的所谓证据。我们建造的人工系统很明显非常脆弱，可能会使我们人类的发展嘠然而止。由人造系统的脆弱无能曾多次使我们蒙羞。 　　我们应当从第一枚原子弹的制造及其引发的军备竞赛中吸取教训。但我们马上又要重蹈覆辙了，与那时情况类似的灾难又要重现人间。 　　制造第一枚原子弹的成就出自天才物理学家罗伯特·奥本海默的杰出领导。奥本海默本非天生就对政治感兴趣，只是他对第三帝国对西方文明的威胁有切肤之痛。由于希特勒可能就要拥有核武器，这一威胁毫无疑问是更加致命的。在此威胁的驱使下，他用自己杰出的智力、对物理学的热情、非凡的领导才能，汇集了无数伟大思想，在洛斯阿拉莫斯成功而又迅速地制造出了第一枚原子弹。 　　令人惊奇的是，在最初的动机消失后，这一工作却偏离了原来的设想！在 V-E Day 之后举行的一次会议上，一些物理学家认为也许要停止对原子弹的研究工作，而奥本海默却坚持要继续进行。他作出这一决定的理由有些奇怪：不是害怕占领日本造成的巨大人员伤亡，而是因为很快强大起来的美国应当掌握原子武器的预备知识。而更有力的原因是 momentum 已经建造完成，第一次原子强试验——三位一体——已经准备就绪了。 　　我们知道在这次原子弹试验中，物理学家要克服大量前所未知的危险。根据爱德华·泰勒的计算，他们起初担心原子弹爆炸会引燃大气层。后来经过修正的计算把毁灭世界的危险降到了一百万分之三（泰勒说他后来放弃了原子弹爆炸会引燃整个大气层的看法）。 　　然而，奥本海默，十分担心三位一体实验的结果，他安排新墨西哥州北部的人们尽量撤离，并且，当然还有开始核军备竞赛的危险。 　　在与第一次成功核试验的同一个月内，两枚原子弹投到了广岛与长崎。一些科学家建议只需要简单演示一下这种炸弹的巨大威力，而不用真正地把它们投到日本的城市，他们以为这样就能极大地增加在战后军备控制的机会。但这个建议没有人理会。只要珍珠港的悲剧仍然历历在目，就不可能让杜鲁门总统仅仅演示一下这种武器，而不把它们投到日本人头上。人们强烈要求尽快结束战争，从而可以拯救那些可能在占领日本的战斗中失去的生命。尽管无视真理可能非常简单，但是，正如物理学家 Freeman Dyson 后来所说，扔下原子弹的原因只是没有人有勇气说“不”！ 　　物理学家们对1945年8月广岛原子弹爆炸的后果是非常震惊的，认识到这一点是非常重要的。他们描述了持续不断的冲击波：首先，炸弹爆炸了，然后现场所有的人在惊恐中死去，接下来人们认为不会再投下另一枚炸弹。然而，另一枚还是在长崎投下了，仅仅在广岛之后三天。 　　在1945年11月，原子弹爆炸后三个月，奥本海默以科学的态度坚持认为：</p>

<p>“_除非你认为世界上的知识及其与之俱来的威力是对人类有真正价值的东西，并且相信你要利用它们来传播知识并作出成绩；否则，你没有必要成为科学家。_”</p>

<p>　　奥本海默和其他人一起完成了《Acheson-Lilienthal报告》。关于这份报告，正如 Richard Rhodes 在他最近写的书《Visions of Technology》中所说的：“在不扩散核武器到世界各国政府手中的情况下找到一种能防止秘密核军备竞赛的方法，”他们的建议是把核武器研制由国家移交到一个国际机构。 　　这一倡议产生了 Barich 计划，并于1946年提交给联合国，但从来没有被采用（可能是因为，就象 Rhodes 建议的，Bernard Baruch “坚持以传统约束力来作为此计划的保障，因此不可避免地使这一计划惨遭厄运，它几乎可以肯定会遭到斯大林主义下的苏联的反对”）。其他一些想通过国际化核武器来防止军备竞赛的努力也是四处踫壁。在内有美国政治家与国内人民之间的互不信任，外有来自苏联的威胁的情况下，避免军备竞赛的机会很快就一去不复返了。 　　在1949年，苏联爆炸了第一枚原子弹。在1955年，美国和苏联试验了适于空投的氢弹。核军备竞赛从此开始了。 　　近20年以前，在《“三位一体”核爆后的时代》一书中，Freeman Dyson 总结了把我们这处世界推入核大战边沿的科学的 attitudes：</p>

<p>“_核武器爆炸时的灿烂光辉是多么迷人，作为一名科学家，你不能抗拒它的诱惑，每个人都能感受到这一点，感受到把这一巨大威力握到自己手中，释放出点燃群星的能量时的自豪。让它们对你俯首贴耳，你能创造这些奇迹，你能把千万吨巨石抛向天空。它给予人们掌握无穷力量的幻想，它能解决我们的一切难题。这就是科学的傲慢，它让人们觉得自己无所不能。_”</p>

<p>　　现在，还有未来，我们是新科技的创造者。我们是未来世界耀眼的明星。在巨大经济回报及全球竞争的驱使下，我们全然不顾迫近的危险，很难预测哪些我们正在创造及构想的事物能在这个世界上不断成长，最终把我们取代。 　　在1947年，《The Bulletin of the Atomic Scientists》杂志开始把“审判日时钟”放在封面上。在长达50年的时间内，它显示了我们面对的核危险的估计值，反映了国际形势的变迁。时钟上的指针已经移动了15次，到今天为止，离午夜只剩下9分钟，反映了核武器对我们持续不断而又迫在眉睫的危险。最近，印度和巴基斯坦加入了核俱乐部，使防止核武器扩散的目标陷于失败，这一危险使得时钟上的指针在1998年前所未有地更接近午夜。 　　在我们的一生中，有多少危险要去面对。难道核武器还不够，还要加上这些科技吗？我们人类灭绝的危险到底有多高？ 　　哲学家 John Searle 经过研究得出人类灭绝的危险至少有30%。然而，雷·库兹维尔（Ray Kurzweil）不顾对他过于乐观态度的指责，依然相信我们更有可能平安无事。但是，这两种态度都不应当提倡，而且他们都没有考虑到另外一引起可能性：那些信誓旦旦不会危害到人类的事物现在都发生了可怕的变化！ 　　面对这样的评估结果，一些严肃的人们已经开始建议我们一有可能就要移民到外星球。我们可以用冯·若伊曼的 probes 来克隆 galaxy 子，从一个星球跳跃到另一个星球，到处繁衍生息。在50亿年后，我们就有需要这样做（或者更短一些，在30亿年后，如果太阳被步步紧逼的仙女座撞击的话）。但是如果我们进入库兹维尔和莫拉维克所说的世界，那到本世纪中叶，我们可能就要这样做了！ 　　这里的道德约做含意是什么？如果我们必须为了种族生存而移居外星，谁该为人类这样的命运负责？（我们自己，after all），谁最后离开？就算我们遍布整个宇宙，难道我们就不会重蹈覆辙吗？或者，在后来发现，老问题依然如影随形吗？我们种族在地球上的命运，我们种族在银河系中的命运，看起来有着解不开的关联。 　　另外一种想法是建立一系列防线来对抗每一种危险的科技。由里根政府提议建造的战略防御计划就是建立一条对付苏联核打击的防线的一个尝试。但知情人 Arthur C. Clarke 认为：</p>

<p>“_假设耗费巨资真能建立起区域防御系统，只要它漏过了很小一部分的弹道导弹，国家保护伞的 touted 就毫无意义。_”</p>

<p>　　路易斯（Luis Alvarez）可能是本世纪最伟大的实验物理学家，向我描述说这些计划的拥护者是一群“没常识的聪明人”。 　　Clarke 接下来说道：</p>

<p>“_盯着我们云翻雾扰的水晶球，我猜想整体防御武器会在一个世纪内成为现实。但同时，其所防御的对象却能象日用品一样从流水线上源源不断地走下来，它们早如此恐怖，以至于我们根本不会为此感到烦恼，就象原始人对弹道导弹毫无感受一样。_”</p>

<p>　　在《创造的引擎》一书中，Eric Drexler 提议我们为生物圈建立一条基于纳米技术的防线，一种免疫系统，以此来防御所有可能从实验室中逃出的危险复制者。但他建议的防线自身也是极其危险的，没有什么能防止它产生发展过度而摧毁生物圈。 　　类似的困难也存在于建立对付机器人技术或基因技术的防线中。这些技术的威力过于强大而难于在有限的时间内加以防御。就算我们有可能能建立这样一条防线，开发其技术的副作用就象我们极力防御的技术一样危险。 　　以上可能发生的事情要不是我们极力反对的，要不就是我们不能完成的，或者两者皆是。在我看来，唯一现实的选择就是放弃、限制那些太过危险的技术研发，限制我们对此类知识的追求。 　　是的，我的确知道知识有助于我们，特别是发现真理的探索。我们从远古时代就开始寻找知道。亚里士多德在其《形而上学》中开篇明义：“人天生求知。”作为我们社会的根本价值，我们对信息获取的知道，并认识到尝度限制获取发展知识所引起的种种问题。在近代，我们开始崇拜科学知识。但是，忽视有力的历史教训，允许自己获取并无限制发展知识，就会使我们陷入物种灭绝的境地，而常识要求我们再次检验甚至很基本的、长久以来奉为圭杲的信念。</p>

<p>　　正是尼采在19世纪末告诫我们的，不仅上帝死了，而且&rdquo;<em>faith in science, which after all exists undeniably, cannot owe its origin to a calculus of utility; it must have originated in spite of the fact that the disutility and dangerousness of the &lsquo;will to truth,&rsquo; of &lsquo;truth at any price&rsquo; is proved to it constantly.</em>&ldquo;我们现在完全面对这种进一步的危险——追求真理导致的后果。科学探索当然可以被认为是“上帝”的危险替代品，如果它可能导致我们灭绝。</p>

<p>　　这是我们现在完全而对的未来的危险。我们追寻真理的结果。如果科学技术追求的真理会使我们亡族灭种，那它就可以被看作危险的“新上帝”。 　　如果我们同意，作为一个物种，我们需要什么？为什么需要它们？我们向哪里进发？为什么是那里？我们才能使我们的未来远离危险，然后我们才有可能知道我能或应当放弃些什么？另外，我们能很容易地开始基于 GNR 技术的军备竞赛，正如在20世纪进行的基于 NBC 技术的军备竞赛。一旦这样的军备竞赛开始，就非常难于停下，这可能是最危险的冒险。 　　我们需要知道，此时此刻，只是我们的恶习、我们的欲望、我们的经济体系，我们的竞争在驱使着我们，而不是象二战时的曼哈顿计划，那时我们面临着不共戴天的敌人对我们文明的致命威胁。 　　我相信我们都希望我们的共同价值观、道德能决定我们的所作所为。如果我们在过去数千年间已经获得了更多的团体智慧，那么对人类的结局展开对话就更加现实，并且我们解除威力难于置信的危险的行动看起来就不象我们想象的那样麻烦。 　　人们可能会想我是出于自我保存的本能而进行这样的对话。很明显，一个人有这样的欲望，然而作为一个物种，我们的行为看上去不象是由我们的好恶所决定。在处理核武器的威胁时，我们经常对自己、对别人撒下弥天大谎，因此使我们面临更大的风险。无论是出于政治动机，或者是因为我们不想多费脑筋，抑或是因为面对如此严重的威胁我们惊慌失措。真正的原因我可能永远不会知道，但这确实不是个好的先例。 　　包含“基因技术、纳米技术、机器人技术”的新潘多拉之盒即将打开，但我们看上去还毫无查觉。一旦打开就很难关上盒子。不象铀或钚，它们不需要开采或提炼，它们能自由拷贝。一旦它们逃脱，它们就再无踪影。虽然是言不由衷的恭维话，丘吉尔强调这样一个事实：美国人民和他们的领导“在检验过每一条可能的道路之后，就会做出正确的决定。”而在这里，我们必须更有先见之明。我们只能做正确的事情，因为一次失误就会让我们全盘皆输。 　　正如 Thorra 所说：</p>

<p>“_我们并不是在高速公路上驾车飞奔；而是被什么东西驾驭着。这个东西就是我们奋力反抗的。现在的问题是，到底谁是谁的主宰？我们能从自己所创造的技术手中幸免于难吗？_”</p>

<p>　　我们正被推入到一个新世纪，没计划、没控制、没刹车。我们已经深陷泥潭了吗？虽然我并不是这样认为，但目前我们没有努力自救，最后用来确保我们能够走上正确道路的机会已经在快速远去。我们已经有了第一台宠物机器人，还拥有了用于商业用途的基因工程技术，并且纳米技术也进展很快。这些技术已经取得了很大进展，不象曼哈顿计划和三位一体核试验，我们不是非要完成最后的步骤，才能证明一项技术深邃而又艰难。在机器人技术、基因工程，或纳米技术中，自我复制的技术突破随时会到来。就象在哺乳动物克隆成功后，我们到那时又会大吃一惊。 　　并且，我相信我们有对希望强烈而又持久的意愿。上个世纪，我们在处理大规模杀伤性武器上的尝试提供了一个光明的先例以供我们参考：美国在没有任何先决条件的情况下单方面放弃了生物武器的开发。这一行动来自于这样的现实状况：当费尽心机开发出恐怖的武器，却有可能被人很容易地复制并流入到无赖国家或恐怖组织手中。 　　有一点很清楚：当我们紧随其后开发用以制造这些武器的技术时，就会给我们增加更大的威胁；而我们不这样干时，我们反而更安全。我们在1972年在生物武器协议上放弃生物武器，并在1993年的化学武器协议上放弃了化学武器。 　　为保持相当大的与我们共存超过50年的核武器威慑力，美国参议院否决了《全面禁止核武器实验公约》，说明放弃核武器并不是一个简单的政治问题，但随着冷战的结束，我们还有一个独一无二的机会来避免多边军备竞赛。 　　基于 BWC 和 CWC 对生物和化学武器的放弃，成功的废除核武器能帮助我们建立放弃危险技术的良好习惯（事实上，只要销毁世界范围内大约100件核武器，就大概相当于二战所有武器摧毁能力的总和，这应当是比较容易完成的任务，我们就能消除核武器对人类的威胁）。 　　事实证明，是否真正放弃危险技术将是件非常困难的任务，但并不是不能解决的问题。我们非常幸运，我们已经在BWC威胁存在的情况下成功完成了类似工作。我们的主要任务将是把以上经验应用到那些本为商业用途开发，但有可能用于军事的技术上。在这里最重要的是透明性。核查的困难程度与从合法的活动中甄别出需要放弃的内容的困难程序直接相关。 　　坦白的说，我认为我们在1945年面临的情况比现在还要简单一些：核技术可以很容易地划分为商业与军事用途，可以藉由检测原子的自然特性来进行监控，并且很容易地测量出其辐射量。进行军事用途的研究必须在国家级的实验室中进行，比如洛斯阿拉莫斯，研究成果会尽可能的秘而不宣。 　　而 GNR 技术不能很清楚地划分为商业和军事用途；它们在商业市场上极具潜力，仅仅在国家级实验室中很难跟踪其技术进度。由于它们有广泛的商业用途，需要一种类似对付生物武器的检测方法来强制某些机构放弃对 GNR 的研发。这一方法不可避免地在个人隐私、知识产权与保证我们全体社会成员的监察要求之间引发冲突。由于失去个人隐私与行动自由，这一方法毫无疑问会受到强烈的反对。 　　监察工作需要科学家与工程师应用严格的伦理指导规范，即与希波克拉底誓言类似的规范，这样他们才有勇气在需要时举起红牌，甚至为此会出极高的个人代价。这将回应50年前广岛、长崎核爆之后由诺贝尔将得主 Hans Bethe（曼哈顿计划资格最老的幸存者之一）的呼吁：“所有科学家放弃并停止创造、发展、改进及生产核武器和其他具有潜在大规模杀伤性能力的武器。”在21世纪，也就是要求那些正在研发 NBC 和 GNR 技术的人们加强个人责任并提高警惕，以避免大规模杀伤性武器和生产大规模杀伤性武器的知识泛滥于世界上。</p>

<p>　　Thoreau 还说道：“_rich in proportion to the number of things which we can afford to let alone._”我们每个人都在寻求快乐，但对此值得发出疑问：我们是否要冒全军覆灭的危险来攫取更多的知识或财富；我们的物质需求是有限有，这是尽人皆知的常识，并且我们都知道某些知识很危险，必须被放弃。</p>

<p>　　我们不应当对这些危险的知识付出代价，不应当对与之同步增长的灭绝危险视而不见。不顾这一切而去追求永生不死。永生不死，也许是我们最初的乌托邦梦想之一，但肯定不是我们唯一的梦想。 　　我最近有幸遇见了杰出的作者、学者 Jacques Attali，他的著作《千僖年》（Lignes d&rsquo;horizons）预先描述了即将到来的无所不在的计算，使我产生了把 Java、Jini 运用到这一领域的灵感。在他的新书《Fraternites》中，描绘了在过去的岁月中，我们的乌托邦之梦曾经经过了怎样的变迁：</p>

<p>“_在科学的萌芽期，人们认为他们在地球上的生活只是一座痛苦的迷宫，在其尽头耸立着死亡之门，通向上帝的宫殿，并进入来世。希伯莱人，还有后来的希腊人勇于从神的统治下解放自己，并梦想有一座充满自由的理想之城。另外一些人注意到了商业发展，他们明白一点点自由都会使人与人之间互相疏离，所以他们寻求的是平等_”。</p>

<p>　　Jacques 使们明白了在我们今天的社会中这三种不同的乌托邦目的是如何相互冲突。他接下来描述了第四种乌托邦，建立在利他主义上的兄弟会。兄弟会把个人的快乐和其他人的快乐联系在一起，定下自助的誓言。 　　这使我对雷·库兹维尔（Ray Kurzweil）的梦想的疑问更加具体化了。通过机器技术来使我们不朽，几乎永生不死的技术可能并不是我们最想要的乌托邦，并且这追求会带来明显的危险。也许我们该重新思考一下我们的乌托邦选择。 　　我们能在哪里发现新的伦理基础来设定前进路线？在喇嘛的著作《新千年的道德》中找到了对我极有启发的灵感。有一点可能广为人知，却少有人特别关注：认为对我们而言，最重要的事情是用对他人的关爱与怜悯来指导我们的生活，我们的社会需要发展出更加坚实的共同责任感和互相依赖的观念。他计划为个人及社会制订出看上去与 Atatali 的 Friternity 友爱乌托邦一致的绝对伦理教条。 　　更进一步认为我们必须明白是什么是人们感到快乐，有明确的证据表明无论是物质进步还是对知识的追求都不是关键，只依靠科学及其追求所能做到的是有限的。 　　我们西方的快乐观念来自于古希腊，定义为“在有限的生命中以充满活力的活动竭力追求卓越。” 　　很明显，我们需要在我产的生命中找到值得去做的的挑战和足够的生存空间与时间，如果我们在无论什么条件下都要寻求快乐的话。但我相信我们必须寻求另外一条道路来发泄我们的创造激情，超越不断的经济增长；这种增长已经极大地造福于我们几个世纪之久，但它并不能给我们带来真正的快乐，我们现在必须在通过科学技术产生的无约束、无方向的增长追求和与之相伴而来的明显的危险之间作出选择。 　　自从我与雷·库兹维尔（Ray Kurzweil）、约翰（John Searle）相会以来已经一年多了。我环视四周，在那些我发现他们曾经和我一样关注我们的困境的人们发妯的要求慎重考虑并放弃危险科技的呼吁声中，我又有了希望。在我的科研经历中，我同时也感受到个人责任的重大意义，不是对我曾经从事的工作，而且是对我可能要去做的工作。 　　但许多人明知某些科技的危险性却仍然保持沉默，当你逼问时，他们只是故作高深地说上一句“这没什么新鲜的”来敷衍了事，就好象只关心一下可能会发生什么就足够了。他们告诉我，大学里到处都是研究此类玩意的生物伦理学家，你提到的那些东西早已经书架蒙尘了，并且都还是大师之作，你所担心的、所争论的已是老生常谈。 　　我不知道这些人把他们的恐惧藏在何处。作为复杂系统的设计师，我是作一名多面手进入这个领域。但这应当减少我的忧虑吗？我深知怎样被如此权威地论述、讨论、演讲时提到，但这就意味着这些危险已经传达给人们了吗？这就意味着我们能减少我们面临的危险了吗？ 　　知而不为是不恰当的。我们能怀疑知识已经成为我们对会自己的武器了吗？ 　　原子物理学家的经验已经清楚地表明需要对太快增长的危险、对那些能甩开人类独自发展的技术方法负起个人责任。我们能，就象某些人曾经做过的那样，创造出没有时间来铲除的不可克服的问题。如果我们不想我们的发明产生的后果产生类似的惊讶与震撼，我们必须要三思而后行。 　　在我的职业生涯中，我一直致力于提高软件的可靠性。软件只是个工具，并且作为工具的建造者，我必须与我创造出的工具应用到的用途斗争。我曾经相信使软件可靠性更高、用途更广，将会使这个世界更加安全与美好，如果我开始与之相反的信念，我就会用道德上的义务来终止我的工作，我现在能想象到这样一天终会到来。 　　当这些都离我而去，虽然我不会怒气冲天，至少也有一丝忧郁。从此以后，科技进步将会叫人患得患失。 　　不知你是否记得在电影《曼哈顿》中的漂亮的倒数第二个场景：伍迪·艾伦躺在长椅上对着录音机口述。他正在写一个短篇故事，讲述了为自己造成了不必要的、神经质的问题的人们，因为他们要从自己宇宙中不可能解决的、可怕的问题中解脱出来。 　　他给自己提出了一个问题：“为什么生命是值得度过？”并且对他而言，考虑到底是什么使得生命值得度过： Grocho Max、Willis Mays、Jupiter 交响曲的第二章、路易斯·阿姆斯特朗的唱片《Potato Head Blues》、瑞典电影、Flaudert 的《感受教育》、马龙·白兰度、Frank Sintra、Cézanne 的苹果和橘子、San Wo 的螃蟹，还有最后被精彩掌声打断的：他的至爱——Tracy 的容貌。 　　我们每个人都有自己心爱的事物。我们关心它们，并把最基本的人性投注到它们身上。最后，我们仍保持乐观，因为我们有能力付出关爱，我们终会反抗我们现在面临的危险。 　　我现在的愿望与来自不同背景的们一与参与关于目前问题的更为广泛的讨论，而不事先基于某种原因假设人们害怕或喜爱技术发展。 　　作为开端，我曾经两次在 Aspen 研究所发起的会议上提出这类问题，并且分别建议对美国艺术与科学学院和 PugWash 会议，把它们纳入自己的工作范围。（自从1957年开始探讨军备控制，特别是核武器，它们就召开了，并制定了可行的政策。） 　　非常不幸的是，PugWash 会议在核武之魔逃出瓶中几乎15年后才开始召开。我们也可能在解决21世纪技术带来的防止知识产生的大规模杀伤性武器问题上动手太迟，如果再不开始行动，就会大势已去，一切就会太晚。</p>

<p>　　所以我仍在不停地探索，我有很多东西要来学习，无论我成功或失败，幸免于难或成为这些技术的牺牲品，都不是命中注定的。我起床又晚了，这时大概是早上6点钟，我努力构想一些更好的答案，我努力打破石化咒语，把我们的回答解释出来。</p>
</blockquote>

<p>　　这篇的原文标题是《How to Build the Global Mind》。其内容比前两篇要乐观一些，诺瓦·斯皮瓦克（Nova Spivack）认为人类可以在全球智能中占据一席之地。</p>

<blockquote>
<p>　　凯文·凯利（Kevin Kelly）最近又写了一篇关于全球超个体存在证据的<a href="https://kk.org/thetechnium/evidence-of-a-g/">绝妙文章</a>。对于正处于发展当中的这个文化基因理论来说，这又是一个有益的贡献。 　　我同意凯文（Kevin Kelly）所说的我们正处于第三阶段的观点。不过我与他的想法有一个重要不同，我认为超个体不仅仅是由机器组成，它同样也由人构成。（请注意，我建议将“统一的机器体系”简称为“统一体”，这便于书写且听起来也很酷） 　　今天，人类仍就是组成这个统一体处理单元的主体。每个人类的神经系统都包含了数以十亿计的处理单元，而地球上又有数十亿的人类。这可是相当多的处理单元了。 　　然而，雷·库兹维尔（Ray Kurzweil）认为处理单元的平衡已经迅速的转向了更受欢迎的机器，也许在随后的半个世纪里，机器处理单元的数目就会超过或至少在计算速度上超过所有人脑处理单元总和，可能还会超过数倍。 　　在赞同库兹维尔（Ray Kurzweil）认为机器智能很快将超越人类智能观点的同时，我对库兹维尔（Ray Kurzweil）列出的时间表表示怀疑，特别是在得知最近有研究表明神经细胞内的微管系统中存在量子级别计算的迹象之后。如果人脑在微管级别的系统中存在计算行为的话，那么人脑中的处理单元数目可能将比现在预计的多出许多个数量级了。不过这个研究结果还有待确认。反对这项研究结果的人称人脑在经典物理层面上能够被模拟，而在这一层面上，量子级别的计算也不需要激发即可进行。我在此明确声明，我不是说人脑就是一台量子计算机，我说的只是有证据表明人脑中进行着量子级别或者接近量子级别的计算过程。量子效应对于人脑进行的工作是否有任何可衡量的影响并不是在本文讨论范围内，我们讨论的仅仅是微管系统是不是人脑中进行处理的最基本单位。如果是，那么人脑中就有比以前预想得多的处理单元。 　　另一点值得注意的就是人脑大部分计算过程不是发生在神经元细胞中，而是发生在突触的间隙之间。计算过程也更多的是通过化学反应而非电位变化。突触比神经元细胞多得多，突触之间进行的计算过程也比神经元传导进行得更快，其过程实现也更充分。化学层面的计算过程所引起的变化也确实比在神经元细胞中进行小上几个数量级。人脑进行计算过程的层次也比我们之前所想得要深。 　　话说回来，人脑进行计算的方式仍未知。我们对此有多种不相伯仲的假想，但是至今还没有最终的答案，不管前面提到的迹象表明了什么，我都认为人脑中的计算过程比我们现在想的更精细。 　　不管怎样，我和库兹维尔（Ray Kurzweil）都同意至少在这个星球上，人工制造的电脑数目将超过天然的人脑，这只是个时间问题。在我看来，实现这个过程要花的时间可能比库兹维尔（Ray Kurzweil）认为的要长一点：最晚可能会在100~200年以后实现吧。 　　在这个课题上，我想的另一些东西可能会在我的作品中引发争议。我不认为我们所说的“思感”（consciousness）可以被人工制造出来。人表现出来思感，但是我们现在都不清楚“思感”意味着什么。无可否认，我们都有过“思感”的经验，这种经验是神秘的，至少到目前为止没人能够让软件程序或者硬件装置看起来具备思感。事实上，我们甚至不知道如何验证“思感”的存在。比如那个备受追捧的图灵测验测试不了思感，它测试的只是类似于人的智慧。还没有哪个测试可以检验思感。对我们来说，开发出一种这样的测试可能是一项重要而又有趣的工作。 　　从我自身的观点来看，思感可能和空间、时间、能量一样对于宇宙本质认识的理解有着根本性帮助。我们不知道空间、时间和能量到底是什么，也不能实际地测量它们。我们所有测量空间、时间以及能量的方法都是间接的——通过测量其他事物来显示空间、时间和能量存在。空间、时间和能量的存在通过它们在我们可以测量的东西上产生影响来体现。同样的方法用于思感也同样有效。问题就是，怎么测量思感对事物所产生的影响？其中一个方法可能就是双缝实验了，这个试验会显示出观察的行为导致量子波函数崩溃的结果。还有其他什么我们能采用的影响结果来作为思感存在的证据吗？ 　　我最近在想思感和我们所处宇宙的本质到底有多大的联系。如果思感是宇宙本质之一，那么我们就无法人为地制造它。就像我们从来都不能制造空间、时间和能量一样，因为它们都是宇宙的本质。 　　如果这是事实的话，那么我们就不可能制造思感。我们所能做的最多也就是引导已经是宇宙本质的思感。事实上，这可能就是人类神经系统所做的工作：它引导思感，这个过程大部分通过电子回路引导电流来实现。软件程序不大可能获得思感是因为他们离宇宙的本质太远。人工智能（AI）程序中认知的高水平显示和其对宇宙物理本质的量子级别演算过程（这个过程可能会具备思感）之间没有或仅有一点点联系。这不同于人的神经系统，在人的神经系统里，基本计算因素和所有认知行为都与宇宙本质直接联系在一起。这至少为思感（软件）、人脑（某种虚拟机器）和量子场（实际的硬件）之间产生双向反馈提供了必要的条件。 　　这也是我最近一直在问我自己的一个问题，思感与物理本质到底有什么联系？更进一步，思感对于我们认识的智能到底有多大的影响？如果思感对于智能很重要，那么人工智能也就不大可能只通过软件来实现，这可能得需要思感，而思感反过来又需要一个不同的计算系统来支持，这个系统与宇宙的量子物理基联系更紧密（通过双向反馈）。 　　这一切对我来说意味着人类可能在统一体——统一的机器体系这个新兴的全球超个体——中组成一个无可取代的重要部分。特别是现在，人类仍然是最智能的部分。但是未来当机械智能超过人类智能数亿、数十亿倍时，人类仍然可以是这个系统中唯一或者至少最有思感的部分。因为人类对于思感独一无二的能力（事实上，动物和昆虫同样有思感），我认为我们在这个新兴的超个体中扮演了一个重要的角色。我们就是它的感觉系统。因为最终我们才是观察、感觉以及了解它所想所做事情的人。 　　因为人类才是统一体所做所想的目击者和知情者，统一体的作用极可能是服务并充实人类，而不是取代人类。这将是一个人类和机器共同协作的系统，目的是为了人类的福祉而非机器的。这种未来愿想非常不同于有些人预想的“终结者式”未来，那些人认为未来机器会聪明到灭绝人类。不会发生那样的事。假如机器能变聪明的话，这也需要很长一段时间内，因为它们不会产生思感。我认为我们应该更应该担心人类毁灭人类自己而非机器。 　　现在转到凯文·凯利（Kevin Kelly）所说的第四层次——“一个具备思感的智能超个体”。我们必须把人类纳入该系统之内，单靠机器不会也不可能让我们达到那个层次。我不相信思感可以被制造，也不相信思感会突然出现在一个合适的复杂电脑系统中。我认为思感是宇宙的本质之一，而电脑程序却在这个本质数层之外。现在我们应该设计一种新的电脑架构，一个能更紧密联系量子场的架构。也许在这样一个系统中，像电流一样，思感才能够被包容。这只是一种可能性。这种系统极有可能更亲近自然，但是这只是个猜想。这是一个有趣的研究方向。 　　不管怎样，如果我们想要将人类纳入这个全球超个体——这个统一体、统一的机器体系之中，那么我们就已经处于Kevin Kelly所说的第四层次上了。如果我们不愿意这么做，那么我不认为你能马上进入第四层次，也许永远也不会了。 　　同样值得注意的是思感跟智能一样分许多层。有仅仅能感觉事物发生的基本的原始思感，也有更强大的思感，比如思感到自己存在的思感、拥有更高决策权的高度精确协调的思感、也有思感到物理本质存在的思感。思感具有和任何其他宇宙本质类似的空间性和虚无性。这些特点其实也是我们所生活在其中的量子本质所具有的。有趣的是这些特性也是现实的特性。佛教大家同样也称这些特性是现实和思维的最终本质。他们并不认为现实和思维是两种不同的事物。思感可能会也可能不会思感到思感和现实本身的这些特性。思感可以很简单、或者很低级、或者根本未觉醒。思感对宇宙本质的感知层次也是一种衡量其层次的方法。我们也称思感的这种能力为“解析度”。思感解析度越高，其对表象的真实本质、宇宙本质的感知也就越精确。当其解析度达到最高点时，思感可以直接认识其观察事物的类似空间、时间的量子本质。思感处于最高解析度时，观察者和被观察事物之间的二元性将消失：思感认知到一切事物都是思感在量子形式下存在的不同表现形式。 　　思感的另一个值得考虑的特点就是我们所说的“统一性”。在最低层次的统一性层面上，根本就没有统一性的概念，有的只是一些极其孤立或单一的个体。而在最高层面上，所有的事物都包含在了一个思感场中。这是一种完全的统一。这种最高阶级我们以“全知”称之。佛教关于精神启示的概念就是一种同时达到最高解析度和最高层次统一度的思感。 　　在我看来，全球超个体已经觉醒，但是它还没有达到高解析度或者高统一性。这是因为大部分人，以及大部分人类群体和组织本身仅仅只能达到最低层次上的思感觉醒。自从人类以及人类群体组成了全球超个体的思感，我们个人和集体的思感进化就和整个超个体的思感进化也就直接联系到了一起。这也是为什么个人以及群体提高自身思感重要的原因。思感在“这儿”作为宇宙本质的一个方面存在，但是和物质、能量一样，思感可以被引导、累积以及塑造。现在我们以及我们所在群体所展示出来的思感大多未开化或者有待发展。 　　在我们这个年轻现实、令人着迷的二元文明中，我们在思感上只取得了极小的进步。取而代之的是我们将大部分精力投入了宇宙的其他本质如空间、时间和能量方面的研究。我认为当一个文明对宇宙本质的思感的研究投入和对其他本质的研究相当时，如果不是更多的话，这个文明也就完全成熟了。这也是我们正在开始做的，多亏量子理论打破了我们经典物理学的桎梏并迫使我们承认思感也许在我们的现实世界中起了一些作用 　　有许多方法可以加速个人和整体的思感进化，这样做可以整体提高我们的文明水平。我最近一直再就这方面的具体情况进行阐述和写作。 　　在个人层次上，提升我们自身思感的一个方法就是通过冥想和精神升华。这是最重要也是最有效的方法。可能有许多技术提升方法，如增强现实和增强感知。它们可以在如何认知以及了解我们所认知事物的深度上帮助我们提升。在不久的将来我们也许可以有机会利用电脑或者生物方法来大幅提高我们感觉器官的广度和解析度。我们甚至可以进化出我们现在无法想象的新感觉。另外，以互联网为例，我们可以在一瞬间知道比以往任何时候都要多的事。但是最终，我们个人的思域将进入内省阶段以便真正获得更高的解析度和统一性。但是这些并不是可以真正提高我们思感的好方法。比如，如果我们可以使用机器去获得更多的信息，但是如果我们的思感仍处于一个相对低水平，那么我们究仍然不能整合或者利用这些信息。 　　众所周知，人脑屏蔽了大部分我们获取的信息。当使用迷幻药品时，大脑的过滤栅会张得更开，这样人们就能感觉到一些以前一直被屏蔽掉的事物。扩大思感广度，增加思感解析度和统一度的结果和吸毒时的感觉类似。除了前者效果更持久，并且可以通过日复一日的强化来控制和增效。我认识的许多西藏喇嘛似乎已经做到了这一点，他们的思域相当宽广，而且其对宇宙的见解也相当准确。他们似乎真的能看到事物的每个细节，甚至是那些最微小的事物，同时他们很少或者根本没有个体观念。个体观念的丧失反过来似乎为他们移除了一些特定的障碍，从而让他们能够感知一些原本超过他们思域感知以外的事情。例如，他们可以感知其他人的想法，预见一些发生在其他地方或时间段的事情。这都可能实现，因为他们思感的解析度和统一性提升了。 　　在整体层面上，同样也有方法能提升群体、组织以及社会的思感，特别是当我们能建立像“自我构建”作用于人一样作用于群体的系统时。 　　自我是虚像，这是个好消息。如果它不是虚像，那么我们永远也不会看透它，也不会获得精神启示。更重要的是，如果它不是虚像，我们就会幻想通过机器或者机器大集合来制造它。佛家、神经学家和认知学家似乎都同意“自我”是虚像这个事实。自我是虚像，它仅仅是一种精神构造。正确地运用它会非常有用。但是没有自我的观念，人类会难以交流，甚至会浑浑噩噩。同样，没有自我归属观念，组织机构和社会同样也无法有效地运行。 　　自我构建与自我模板、自身环境一道构成一体。这个模板包括发生在“内部”和“外部”的事，以及自我和“我”的观念。通过制造这种人为的界限和模式化发生在界限两边的事情，自我构建能够测量和规划行为的尺度，并能使一个系统改善和适应“自己”以及外部环境。具备自我构建能力的个体表现得远比那些不具备这种能能力的个体智能，想想人和狗的智能吧。在这两个物种之间在智能上的差距其实就是自我构建能力之间的差距。人类比狗更自觉、更自省也更成熟。它们都有思感，但是人类自我构建能力更高。这个道理对于简单的人工智能程序和诸如工作组、企业以及网络社区的集体智能同样适用。自我构建功能越成熟，其系统就越聪明。 　　合理而有效地运用自我架构的关键在于发展出一个健康的自我，而不是完全湮灭自我的存在。湮灭自我会造成一种虚无主义，从而导致个体无法在这个世界上生存。这可不是佛家或者神经学家提倡的了。那么怎样才算一个健康的自我呢？对于个人来说，一个健康的自我就是能表里如一地对过去、现在和预计好的未来有一个清晰的反映；高度自觉、理性但不自负，而应带着适应的尊敬的眼光看待外部世界和其他事物；思想开放、善于学习和为适应新环境而改变。这同样适用于一个健康的集体。但是，当今大部分人并没有一个健康的自我，他们有的是极度阴暗、不健康的自我。这反过来在更高层次上影响了我们建立的群体、组织和社会的自我构建。 　　现在我们能做的最重要的一件事就是——创造能为诸如群体、组织和社会等集体提供虚拟自我的系统。这些虚拟自我为这些集体提供镜子，从而让这些系统中的成员可以看见整体，以及他们在其中的适应情况。一旦看到这些，他们就能开始调整自己的行为以适应整体的发展方向。这个简单的反射功能能够促使其在自我管理上上一个新的台阶，并使原来混乱不堪的单个个体“群落”动作协调起来。 　　事实上，我认为集体的发展有三个阶段： 　　第一阶段：群落（Crowds） 　　在这种组织形式中，其组成个体并没有思感到整体的存在，对身份和目标也没有统一的概念。然而它也有思感的做某些事，例如，鱼群或者鸟群。它们没有首领，但是这些个体通过适应它们周围同类所做的事情，从而从整体上看起来像某种意义上的单体。群落形态就和一团以斑状外形存在的阿米巴实体一样。这和气体的物理模型没多大差别。 　　第二阶段：群体（Groups） 　　群落的下一发展阶段就是群体了。群体的一些结构经常包含一个命令和控制系统。这中组织形态更严密。群体能够表现出更多的目的性和智能行为。家庭、城市、工作组、运动队、军队、大学、公司和国家等都是群体。大部分群体具备和低级动物相当的智能。他们可能具有身份和自我的概念，基于此，它们计划和行动显得更一致。 　　第三阶段：元个体（Meta-Individuals） 　　集体智能的最高阶段是元个体。这开始于曾经是群落中孤立的个体在根据自身特点进化为一个新个体时，一个成熟的元层面上的自我构建系统从整体考虑将其重新组合。这种进化成为元系统转化——不见通过变换组合后形成一个更高级的新整体。这个新整体重组了部件，但是改变了部件的功能。一个集体要进化成为真正的个体，它需要具备整体头脑和意志。最重要的是，它还必须形成高层次的集体思感。高层次集体思感的形成需要一个成熟的集体自我构建功能来作为催化剂。幸运的是，这是我们能够创建的，因为如之前所述，自我是虚像，是一种构造，因此自我能够被建造出来，即使对于包含数百万或者数十亿成员的大集体来说也是如此。</p>

<p>　　全球超个体已经被一群先见者称为“全球大脑”超过一个世纪。今天我们也许可以开始称它为“统一的机器体系”，或者统一体，或者其他名字。但是不管怎样，我认为我们能做的作重要的工作就是提供一个更高级更准确意义上的集体自我来让它变得更聪明了。为此我们也许应该让一些小得多集体如群落、团队、企业和在线社区发展起来更好的自我。我们能够指引并促进它们进入更高的集体思感和自我管理层面吗？我非常相信这是有可能的，我也肯定科技进步将支持这一目标的实现。</p>
</blockquote>

<p><strong>俺博客上，和本文相关的帖子（需翻墙）</strong>：</p>

<p><a href="https://program-think.blogspot.com/2016/03/AlphaGo.html">聊聊大伙儿（包括某些职业围棋手）对 AlphaGo 的误解</a><br />
<a href="https://program-think.blogspot.com/2017/01/weekly-share-107.html">每周转载：AlphaGo 超快棋遍虐人类高手（职业棋手讲解及大量网友评论）</a><br />
<a href="https://program-think.blogspot.com/2013/01/weekly-share-37.html">每周转载：关于黑客文化和黑客精神</a></p>

            </div>
            
        </div>
    </div>
</div>


    </div>
</div>

<footer class="footer has-background-grey-darker has-text-white">
    <div class="content has-text-centered">
        <p>
            <br><br>
            <span>友链：<a href="http://www.xys.org/">新语丝</a>
                <span> </span><a href="https://twitter.com/fangshimin">方舟子Twitter</a>
            </span>
            <br><br>
            Copyright &copy; 编程随想镜像站 2021
        </p>
    </div>
</footer>

<script defer src="https://use.fontawesome.com/releases/v5.1.0/js/all.js"></script>
</body>

</html>